_storage {
  type = postgres
  config {
     dataSourceClass = "org.postgresql.ds.PGSimpleDataSource"
     properties = {
       serverName = ${?DB_SERVER}
       portNumber = 5432
       databaseName = participant
       currentSchema = participant
       user =  ${?DB_USER}
       password = ${?DB_PASSWORD}
       tcpKeepAlive = true
     }
   }
   parameters {
     max-connections = 32
     migrate-and-start = true
   }
 }

canton {
  features {
    enable-preview-commands = yes
    enable-testing-commands = yes
  }
  parameters {
    manual-start = no
    non-standard-config = yes
    # Bumping because our topology state can get very large due to
    # a large number of participants.
    timeouts.processing.verify-active = 40.seconds
    timeouts.processing.slow-future-warn = 20.seconds
  }

  # Bumping because our topology state can get very large due to
  # a large number of participants.
  monitoring.logging.delay-logging-threshold = 40.seconds
}


_participant {
  init {
    generate-topology-transactions-and-keys = false
    identity.type = manual
  }

  monitoring.grpc-health-server {
    address = "0.0.0.0"
    port = 5061
  }
  storage = ${_storage}

  admin-api {
    address = "0.0.0.0"
    port = 5002
  }

  init.ledger-api.max-deduplication-duration = 30s

  ledger-api {
    # TODO(DACH-NY/canton-network-internal#2347) Revisit this; we want to avoid users to have to set an exp field in their tokens
    max-token-lifetime = Inf
    # Required for pruning
    admin-token-config.admin-claim=true
    address = "0.0.0.0"
    port = 5001

    # We need to bump this because we run one stream per user +
    # polling for domain connections which can add up quite a bit
    # once you're around ~100 users.
    rate-limit.max-api-services-queue-size = 80000
    interactive-submission-service {
      enable-verbose-hashing = true
    }
  }

  http-ledger-api {
    port = 7575
    address = 0.0.0.0
    path-prefix = ${?CANTON_PARTICIPANT_JSON_API_SERVER_PATH_PREFIX}
  }

  parameters {
    initial-protocol-version = 34
    # tune the synchronisation protocols contract store cache
    caching {
      contract-store {
        maximum-size = 1000 # default 1e6
        expire-after-access = 120s # default 10 minutes
      }
    }
    # Bump ACS pruning interval to make sure ACS snapshots are available for longer
    journal-garbage-collection-delay = 24h
  }

  # TODO(DACH-NY/canton-network-node#8331) Tune cache sizes
  # from https://docs.daml.com/2.8.0/canton/usermanual/performance.html#configuration
  # tune caching configs of the ledger api server
  ledger-api {
    index-service {
      max-contract-state-cache-size = 1000 # default 1e4
      max-contract-key-state-cache-size = 1000 # default 1e4

      # The in-memory fan-out will serve the transaction streams from memory as they are finalized, rather than
      # using the database. Therefore, you should choose this buffer to be large enough such that the likeliness of
      # applications having to stream transactions from the database is low. Generally, having a 10s buffer is
      # sensible. Therefore, if you expect e.g. a throughput of 20 tx/s, then setting this number to 200 is sensible.
      # The default setting assumes 100 tx/s.
      max-transactions-in-memory-fan-out-buffer-size = 200 # default 1000
    }
    # Restrict the command submission rate (mainly for SV participants, since they are granted unlimited traffic)
    command-service.max-commands-in-flight = 30 # default = 256
  }

  monitoring.http-health-server {
    address="0.0.0.0"
    port=7000
  }

  topology.broadcast-batch-size = 1
}

include file("/app/app-provider/on/app.conf")
include file("/app/app-provider/on/app-auth.conf")
include file("/app/app-user/on/app.conf")
include file("/app/app-user/on/app-auth.conf")
include file("/app/sv/on/app.conf")
include file("/app/sv/on/app-auth.conf")
